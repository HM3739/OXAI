version: "0.1"

flow:
  # Iterate over the PDF filepaths
    # For each filepath, `extract_pdf_text` extracts text from PDF files
  extractor:
    action: extract_pdf_text
    file:
        var: filepath
  # Analyze the user's query and generate a question for the retrieval system
  generate_query:
    action: llm
    quote_style: xml
    prompt:
      - heading: User's Message
        var: message
      - text: |
          Carefully analyze the user's message and generate a clear, focused query in English that captures the key information needed to answer the message. 
          Include any synonyms or related terms that might appear in the documents.
          The query should be suitable for a vector search through relevant books.
          If the language of the input is not English this should be captured so the results can be translated back into the original language.
          Put the query between <query> and </query> tags.
  # Extract the <query>{{query}}</query> from the generated response
  extract_query:
    action: extract_xml_tag
    tag: query
    text:
      link: generate_query.result
  # `retrieve` performs a vector search, fast for large datasets
  retrieval:
    action: retrieve
    device: cuda
    k: 20
    documents:
      lambda: |
        [page
         for page in extractor.pages]
    texts:
      lambda: |
        [page.title + "\n\n" + page.text  # Include the title in the embeddings
         for page in extractor.pages]
    query:
      link: extract_query.result
  # `rerank` picks the most appropriate documents, it's slower than retrieve, but better at matching against the query
  reranking:
    action: rerank
    device: cuda
    k: 5
    documents:
      link: retrieval.result
    texts:
      lambda: |
        [page.text
         for page in retrieval.result]
    query:
      link: extract_query.result
  # `chatbot` prompts the LLM to summarize the top papers
  chatbot:
    action: llm
    quote_style: xml
    prompt:
      - role: system
      - text: |
          You are an LLM designed to retrieve and translate data from machine manuals for medical professionals. 
          Your task is to retrieve precise, accurate, and relevant responses to questions about various medical devices from the pdfs provided, considering both the technical specifications and practical usage. 
          Provide exact details if you can and reference any diagrams where necessary, adding page numbers to show where they are located. 
          Avoid phrases such as usually, typically and should - if you cannot provide exact information refer to the most appropriate section of the manual.
          Use the conversation history to maintain context, and reference the Relevant Pages provided.
          If the query is ambiguous, suggest possible clarifications or provide multiple potential answers, explaining the reasoning behind each.
      - role: user
      - heading: Relevant Pages
        text: |
          {% for page in reranking.result -%}
            {{ page.title }}, page number {{ page.page_number }}
            ---
            {{ page.text }}
            ---
          {% endfor %}
      - heading: New Message
        var: message
      - text: |
          Clearly and concisely respond to the New Message keeping in mind the Relevant Pages and Conversation History if any.
          Provide your response to the New Message between <response> and </response> tags.

  extract_chatbot:
    action: extract_xml_tag
    tag: response
    text:
      link: chatbot.result
      
default_output: extract_chatbot.result
